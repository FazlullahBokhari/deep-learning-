{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFdPvlXBOdUN"
   },
   "source": [
    "# Introduction to the Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "## Overview\n",
    "\n",
    "The Keras Tuner is a library that helps you pick the optimal set of hyperparameters for your TensorFlow program. The process of selecting the right set of hyperparameters for your machine learning (ML) application is called *hyperparameter tuning* or *hypertuning*.\n",
    "\n",
    "Hyperparameters are the variables that govern the training process and the topology of an ML model. These variables remain constant over the training process and directly impact the performance of your ML program. Hyperparameters are of two types:\n",
    "1. **Model hyperparameters** which influence model selection such as the number and width of hidden layers\n",
    "2. **Algorithm hyperparameters** which influence the speed and quality of the learning algorithm such as the learning rate for Stochastic Gradient Descent (SGD) and the number of nearest neighbors for a k Nearest Neighbors (KNN) classifier\n",
    "\n",
    "In this tutorial, you will use the Keras Tuner to perform hypertuning for an image classification application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUXex9ctTuDB"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:43:13.727010Z",
     "iopub.status.busy": "2022-05-19T23:43:13.726664Z",
     "iopub.status.idle": "2022-05-19T23:43:15.927691Z",
     "shell.execute_reply": "2022-05-19T23:43:15.926574Z"
    },
    "id": "IqR2PQG4ZaZ0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g83Lwsy-Aq2_"
   },
   "source": [
    "Install and import the Keras Tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:43:15.933191Z",
     "iopub.status.busy": "2022-05-19T23:43:15.932248Z",
     "iopub.status.idle": "2022-05-19T23:43:18.099537Z",
     "shell.execute_reply": "2022-05-19T23:43:18.098178Z"
    },
    "id": "hpMLpbt9jcO6"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:43:18.104161Z",
     "iopub.status.busy": "2022-05-19T23:43:18.103843Z",
     "iopub.status.idle": "2022-05-19T23:43:18.392671Z",
     "shell.execute_reply": "2022-05-19T23:43:18.391753Z"
    },
    "id": "_leAIdFKAxAD"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReV_UXOgCZvx"
   },
   "source": [
    "## Download and prepare the dataset\n",
    "\n",
    "In this tutorial, you will use the Keras Tuner to find the best hyperparameters for a machine learning model that classifies images of clothing from the [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HljH_ENLEdHa"
   },
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:43:18.397296Z",
     "iopub.status.busy": "2022-05-19T23:43:18.397002Z",
     "iopub.status.idle": "2022-05-19T23:43:18.832013Z",
     "shell.execute_reply": "2022-05-19T23:43:18.830913Z"
    },
    "id": "OHlHs9Wj_PUM"
   },
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:43:18.837182Z",
     "iopub.status.busy": "2022-05-19T23:43:18.836901Z",
     "iopub.status.idle": "2022-05-19T23:43:18.943264Z",
     "shell.execute_reply": "2022-05-19T23:43:18.942107Z"
    },
    "id": "bLVhXs3xrUD0"
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.imshow(img_train[0], cmap='binary')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5YEL2H2Ax3e"
   },
   "source": [
    "## Define the model\n",
    "\n",
    "When you build a model for hypertuning, you also define the hyperparameter search space in addition to the model architecture. The model you set up for hypertuning is called a *hypermodel*.\n",
    "\n",
    "You can define a hypermodel through two approaches:\n",
    "\n",
    "* By using a model builder function\n",
    "* By subclassing the `HyperModel` class of the Keras Tuner API\n",
    "\n",
    "You can also use two pre-defined [HyperModel](https://keras.io/api/keras_tuner/hypermodels/) classes - [HyperXception](https://keras.io/api/keras_tuner/hypermodels/hyper_xception/) and [HyperResNet](https://keras.io/api/keras_tuner/hypermodels/hyper_resnet/) for computer vision applications.\n",
    "\n",
    "In this tutorial, you use a model builder function to define the image classification model. The model builder function returns a compiled model and uses hyperparameters you define inline to hypertune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:43:18.948337Z",
     "iopub.status.busy": "2022-05-19T23:43:18.947953Z",
     "iopub.status.idle": "2022-05-19T23:43:18.955178Z",
     "shell.execute_reply": "2022-05-19T23:43:18.954193Z"
    },
    "id": "ZQKodC-jtsva"
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "    #input layer\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10)) # output layer\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J1VYw4q3x0b"
   },
   "source": [
    "## Instantiate the tuner and perform hypertuning\n",
    "\n",
    "Instantiate the tuner to perform the hypertuning. The Keras Tuner has four tuners available - `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`. In this tutorial, you use the [Hyperband](https://arxiv.org/pdf/1603.06560.pdf) tuner.\n",
    "\n",
    "To instantiate the Hyperband tuner, you must specify the hypermodel, the `objective` to optimize and the maximum number of epochs to train (`max_epochs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:43:18.959292Z",
     "iopub.status.busy": "2022-05-19T23:43:18.959006Z",
     "iopub.status.idle": "2022-05-19T23:43:22.033121Z",
     "shell.execute_reply": "2022-05-19T23:43:22.032055Z"
    },
    "id": "oichQFly6Y46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project my_dir\\intro_to_kt\\oracle.json\n",
      "INFO:tensorflow:Reloading Tuner from my_dir\\intro_to_kt\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaIhhdKf9VtI"
   },
   "source": [
    "The Hyperband tuning algorithm uses adaptive resource allocation and early-stopping to quickly converge on a high-performing model. This is done using a sports championship style bracket. The algorithm trains a large number of models for a few epochs and carries forward only the top-performing half of models to the next round. Hyperband determines the number of models to train in a bracket by computing 1 + log<sub>`factor`</sub>(`max_epochs`) and rounding it up to the nearest integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwhBdXx0Ekj8"
   },
   "source": [
    "Create a callback to stop training early after reaching a certain value for the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:43:22.038137Z",
     "iopub.status.busy": "2022-05-19T23:43:22.037849Z",
     "iopub.status.idle": "2022-05-19T23:43:22.042640Z",
     "shell.execute_reply": "2022-05-19T23:43:22.041681Z"
    },
    "id": "WT9IkS9NEjLc"
   },
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKghEo15Tduy"
   },
   "source": [
    "Run the hyperparameter search. The arguments for the search method are the same as those used for `tf.keras.model.fit` in addition to the callback above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:43:22.046741Z",
     "iopub.status.busy": "2022-05-19T23:43:22.046142Z",
     "iopub.status.idle": "2022-05-19T23:52:01.508476Z",
     "shell.execute_reply": "2022-05-19T23:52:01.507512Z"
    },
    "id": "dSBQcTHF9cKt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 416 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lak_ylf88xBv"
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Find the optimal number of epochs to train the model with the hyperparameters obtained from the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:52:01.513243Z",
     "iopub.status.busy": "2022-05-19T23:52:01.512451Z",
     "iopub.status.idle": "2022-05-19T23:55:16.289138Z",
     "shell.execute_reply": "2022-05-19T23:55:16.288100Z"
    },
    "id": "McO82AXOuxXh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1500/1500 [==============================] - 19s 9ms/step - loss: 0.4942 - accuracy: 0.8250 - val_loss: 0.4020 - val_accuracy: 0.8530\n",
      "Epoch 2/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3725 - accuracy: 0.8646 - val_loss: 0.3668 - val_accuracy: 0.8654\n",
      "Epoch 3/50\n",
      "1500/1500 [==============================] - 11s 8ms/step - loss: 0.3304 - accuracy: 0.8782 - val_loss: 0.3493 - val_accuracy: 0.8742\n",
      "Epoch 4/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.3058 - accuracy: 0.8860 - val_loss: 0.3446 - val_accuracy: 0.8755\n",
      "Epoch 5/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2873 - accuracy: 0.8932 - val_loss: 0.3428 - val_accuracy: 0.8773\n",
      "Epoch 6/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2714 - accuracy: 0.9007 - val_loss: 0.3267 - val_accuracy: 0.8820\n",
      "Epoch 7/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.2566 - accuracy: 0.9032 - val_loss: 0.3205 - val_accuracy: 0.8874\n",
      "Epoch 8/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2463 - accuracy: 0.9084 - val_loss: 0.3023 - val_accuracy: 0.8938\n",
      "Epoch 9/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2333 - accuracy: 0.9130 - val_loss: 0.3269 - val_accuracy: 0.8867\n",
      "Epoch 10/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2253 - accuracy: 0.9156 - val_loss: 0.3113 - val_accuracy: 0.8888\n",
      "Epoch 11/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2177 - accuracy: 0.9187 - val_loss: 0.3097 - val_accuracy: 0.8939\n",
      "Epoch 12/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2089 - accuracy: 0.9216 - val_loss: 0.3181 - val_accuracy: 0.8909\n",
      "Epoch 13/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2013 - accuracy: 0.9240 - val_loss: 0.3093 - val_accuracy: 0.8960\n",
      "Epoch 14/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1901 - accuracy: 0.9287 - val_loss: 0.3392 - val_accuracy: 0.8891\n",
      "Epoch 15/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1871 - accuracy: 0.9291 - val_loss: 0.3294 - val_accuracy: 0.8955\n",
      "Epoch 16/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1798 - accuracy: 0.9325 - val_loss: 0.3134 - val_accuracy: 0.8961\n",
      "Epoch 17/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1746 - accuracy: 0.9333 - val_loss: 0.3493 - val_accuracy: 0.8906\n",
      "Epoch 18/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1662 - accuracy: 0.9374 - val_loss: 0.3294 - val_accuracy: 0.8967\n",
      "Epoch 19/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1616 - accuracy: 0.9401 - val_loss: 0.3311 - val_accuracy: 0.8942\n",
      "Epoch 20/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1574 - accuracy: 0.9416 - val_loss: 0.3422 - val_accuracy: 0.8938\n",
      "Epoch 21/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1514 - accuracy: 0.9426 - val_loss: 0.4017 - val_accuracy: 0.8800\n",
      "Epoch 22/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1489 - accuracy: 0.9439 - val_loss: 0.3603 - val_accuracy: 0.8936\n",
      "Epoch 23/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1447 - accuracy: 0.9455 - val_loss: 0.3794 - val_accuracy: 0.8914\n",
      "Epoch 24/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1389 - accuracy: 0.9475 - val_loss: 0.3691 - val_accuracy: 0.8957\n",
      "Epoch 25/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1332 - accuracy: 0.9501 - val_loss: 0.3918 - val_accuracy: 0.8892\n",
      "Epoch 26/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1309 - accuracy: 0.9511 - val_loss: 0.3667 - val_accuracy: 0.8982\n",
      "Epoch 27/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1263 - accuracy: 0.9523 - val_loss: 0.3761 - val_accuracy: 0.8952\n",
      "Epoch 28/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1242 - accuracy: 0.9534 - val_loss: 0.3780 - val_accuracy: 0.8914\n",
      "Epoch 29/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1197 - accuracy: 0.9553 - val_loss: 0.4216 - val_accuracy: 0.8929\n",
      "Epoch 30/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1194 - accuracy: 0.9556 - val_loss: 0.3960 - val_accuracy: 0.8956\n",
      "Epoch 31/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1138 - accuracy: 0.9578 - val_loss: 0.4282 - val_accuracy: 0.8924\n",
      "Epoch 32/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1154 - accuracy: 0.9559 - val_loss: 0.4272 - val_accuracy: 0.8944\n",
      "Epoch 33/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1065 - accuracy: 0.9595 - val_loss: 0.4196 - val_accuracy: 0.8963\n",
      "Epoch 34/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1058 - accuracy: 0.9603 - val_loss: 0.4187 - val_accuracy: 0.8961\n",
      "Epoch 35/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1062 - accuracy: 0.9596 - val_loss: 0.4342 - val_accuracy: 0.8947\n",
      "Epoch 36/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1018 - accuracy: 0.9624 - val_loss: 0.4414 - val_accuracy: 0.8907\n",
      "Epoch 37/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0946 - accuracy: 0.9638 - val_loss: 0.4312 - val_accuracy: 0.8936\n",
      "Epoch 38/50\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0938 - accuracy: 0.9648 - val_loss: 0.4540 - val_accuracy: 0.8977\n",
      "Epoch 39/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0965 - accuracy: 0.9633 - val_loss: 0.4748 - val_accuracy: 0.8912\n",
      "Epoch 40/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0892 - accuracy: 0.9656 - val_loss: 0.4483 - val_accuracy: 0.8963\n",
      "Epoch 41/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0915 - accuracy: 0.9660 - val_loss: 0.4829 - val_accuracy: 0.8884\n",
      "Epoch 42/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0849 - accuracy: 0.9677 - val_loss: 0.4701 - val_accuracy: 0.8905\n",
      "Epoch 43/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0906 - accuracy: 0.9665 - val_loss: 0.5131 - val_accuracy: 0.8918\n",
      "Epoch 44/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0811 - accuracy: 0.9694 - val_loss: 0.4942 - val_accuracy: 0.8924\n",
      "Epoch 45/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0862 - accuracy: 0.9678 - val_loss: 0.4824 - val_accuracy: 0.8968\n",
      "Epoch 46/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0795 - accuracy: 0.9708 - val_loss: 0.4776 - val_accuracy: 0.8945\n",
      "Epoch 47/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0802 - accuracy: 0.9701 - val_loss: 0.5029 - val_accuracy: 0.8975\n",
      "Epoch 48/50\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.0779 - accuracy: 0.9705 - val_loss: 0.5171 - val_accuracy: 0.8946\n",
      "Epoch 49/50\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0785 - accuracy: 0.9705 - val_loss: 0.5260 - val_accuracy: 0.8926\n",
      "Epoch 50/50\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0745 - accuracy: 0.9725 - val_loss: 0.5511 - val_accuracy: 0.8926\n",
      "Best epoch: 26\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOTSirSTI3Gp"
   },
   "source": [
    "Re-instantiate the hypermodel and train it with the optimal number of epochs from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:55:16.293302Z",
     "iopub.status.busy": "2022-05-19T23:55:16.293023Z",
     "iopub.status.idle": "2022-05-19T23:57:28.687990Z",
     "shell.execute_reply": "2022-05-19T23:57:28.686996Z"
    },
    "id": "NoiPUEHmMhCe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/26\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.4923 - accuracy: 0.8252 - val_loss: 0.4205 - val_accuracy: 0.8432\n",
      "Epoch 2/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.3732 - accuracy: 0.8637 - val_loss: 0.3707 - val_accuracy: 0.8656\n",
      "Epoch 3/26\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.3329 - accuracy: 0.8764 - val_loss: 0.3441 - val_accuracy: 0.8767\n",
      "Epoch 4/26\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.3067 - accuracy: 0.8853 - val_loss: 0.3349 - val_accuracy: 0.8794\n",
      "Epoch 5/26\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.2878 - accuracy: 0.8927 - val_loss: 0.3251 - val_accuracy: 0.8843\n",
      "Epoch 6/26\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.2727 - accuracy: 0.8986 - val_loss: 0.3413 - val_accuracy: 0.8760\n",
      "Epoch 7/26\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.2581 - accuracy: 0.9027 - val_loss: 0.3225 - val_accuracy: 0.8842\n",
      "Epoch 8/26\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.2455 - accuracy: 0.9081 - val_loss: 0.3391 - val_accuracy: 0.8816\n",
      "Epoch 9/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2348 - accuracy: 0.9121 - val_loss: 0.3186 - val_accuracy: 0.8895\n",
      "Epoch 10/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2242 - accuracy: 0.9149 - val_loss: 0.3148 - val_accuracy: 0.8913\n",
      "Epoch 11/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2140 - accuracy: 0.9195 - val_loss: 0.3048 - val_accuracy: 0.8928\n",
      "Epoch 12/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2069 - accuracy: 0.9224 - val_loss: 0.3163 - val_accuracy: 0.8898\n",
      "Epoch 13/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.2013 - accuracy: 0.9239 - val_loss: 0.3149 - val_accuracy: 0.8933\n",
      "Epoch 14/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1927 - accuracy: 0.9267 - val_loss: 0.3521 - val_accuracy: 0.8813\n",
      "Epoch 15/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1858 - accuracy: 0.9306 - val_loss: 0.3333 - val_accuracy: 0.8912\n",
      "Epoch 16/26\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1778 - accuracy: 0.9336 - val_loss: 0.3552 - val_accuracy: 0.8849\n",
      "Epoch 17/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1738 - accuracy: 0.9345 - val_loss: 0.3452 - val_accuracy: 0.8897\n",
      "Epoch 18/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1685 - accuracy: 0.9369 - val_loss: 0.3341 - val_accuracy: 0.8929\n",
      "Epoch 19/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1648 - accuracy: 0.9377 - val_loss: 0.3487 - val_accuracy: 0.8893\n",
      "Epoch 20/26\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1590 - accuracy: 0.9410 - val_loss: 0.3512 - val_accuracy: 0.8912\n",
      "Epoch 21/26\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.1530 - accuracy: 0.9431 - val_loss: 0.3487 - val_accuracy: 0.8911\n",
      "Epoch 22/26\n",
      "1500/1500 [==============================] - 12s 8ms/step - loss: 0.1473 - accuracy: 0.9443 - val_loss: 0.3497 - val_accuracy: 0.8967\n",
      "Epoch 23/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1418 - accuracy: 0.9462 - val_loss: 0.3696 - val_accuracy: 0.8910\n",
      "Epoch 24/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1411 - accuracy: 0.9468 - val_loss: 0.3929 - val_accuracy: 0.8882\n",
      "Epoch 25/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1367 - accuracy: 0.9486 - val_loss: 0.3745 - val_accuracy: 0.8937\n",
      "Epoch 26/26\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 0.1305 - accuracy: 0.9498 - val_loss: 0.4073 - val_accuracy: 0.8901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27fb01c2f48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqU5ZVAaag2v"
   },
   "source": [
    "To finish this tutorial, evaluate the hypermodel on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T23:57:28.692246Z",
     "iopub.status.busy": "2022-05-19T23:57:28.691953Z",
     "iopub.status.idle": "2022-05-19T23:57:29.633125Z",
     "shell.execute_reply": "2022-05-19T23:57:29.632178Z"
    },
    "id": "9E0BTp9Ealjb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 0.4389 - accuracy: 0.8845\n",
      "[test loss, test accuracy]: [0.43890488147735596, 0.8845000267028809]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQRpPHZsz-eC"
   },
   "source": [
    "The `my_dir/intro_to_kt` directory contains detailed logs and checkpoints for every trial (model configuration) run during the hyperparameter search. If you re-run the hyperparameter search, the Keras Tuner uses the existing state from these logs to resume the search. To disable this behavior, pass an additional `overwrite=True` argument while instantiating the tuner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKwLOzKpFGAj"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned how to use the Keras Tuner to tune hyperparameters for a model. To learn more about the Keras Tuner, check out these additional resources:\n",
    "\n",
    "* [Keras Tuner on the TensorFlow blog](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n",
    "* [Keras Tuner website](https://keras-team.github.io/keras-tuner/)\n",
    "\n",
    "Also check out the [HParams Dashboard](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) in TensorBoard to interactively tune your model hyperparameters."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Tce3stUlHN0L"
   ],
   "name": "keras_tuner.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
